# 🧠MaiMBot-LPMM-Demo

这里是MaiMBot项目的长期与持久化记忆（Long-term and Persistent Memory）模块，负责麦麦的事件记忆与知识点学习，相当于人脑的海马体与新皮层。

> [!WARNING]
> **注意：此处为模块早期开发Demo，不能直接应用到MaiMBot项目中**

## 🎯开发计划

1. 基于[`HippoRAG 2`](https://github.com/OSU-NLP-Group/HippoRAG)的知识图谱系统：
    - [x] 学习：离线增量式学习；（99% - 部分函数等待测试）
    - [x] 检索：在线图检索与PageRank；（100%）
2. 拟人脑的遗忘机制：
    - [ ] 对使用少的记忆片段进行压缩，减少空间占用和token使用；（0%）
      - [ ] 设计模糊化阈值，当记忆片段的使用频率低于阈值时，会被压缩；（0%）
    - [ ] 当记忆发生遗忘时，相应节点/边不会立即被删除，而是被标记为“遗忘”，当某次记忆构建再次检索到该节点时，节点会被重新激活并被赋予更高的权重（模拟人的遗忘后再记起会加深印象）；（0%）
    - [ ] 使用LRU序列对记忆节点和边进行管理，定期剪枝，减少空间占用和图谱检索用时；（0%）
      - [ ] 设计遗忘系数，随图谱的膨胀而增大，避免图谱膨胀导致的检索时间退化；（0%）
      - [ ] 设计保护阈值，当图谱的节点数超过阈值时，会自动触发已遗忘节点的释放，避免图谱无限制膨胀导致空间占用失控；（0%）
3. 图谱管理WebUI：
    - [ ] 基于[networkx](https://networkx.org/)的图谱动态可视化系统；（0%）
      - [ ] 支持图谱的增删改查；（0%）
      - [ ] 支持图谱的导入导出；（0%）
4. 人因评估：
    - [ ] 引入人类反馈，对记忆检索的结果、记忆片段的有效性进行反馈，强化学习；（0%）
5. 其它：
    - [ ] 细胞知识库：允许用户导入自己的知识图谱，与已有的知识图谱进行融合；（0%）

## ❤️致谢

- [HippoRAG](https://github.com/OSU-NLP-Group/HippoRAG): 为本项目提供了知识图谱基础框架的灵感；
- Github Copilot: 为本项目提供了代码解读与代码提示；

## ⚙️原理

LPMM模块基于`HippoRAG 2`构建，使用`RAG`模型进行知识图谱的构建与检索。`HippoRAG 2`是一个基于`海马体索引`理论的知识图谱构建与检索增强生成系统，支持离线增量式学习、在线智能检索等功能。

### 1. 离线学习

1. **预处理**

    对于提供的文本数据，LPMM会先对文本进行预处理，具体如下：

    - 哈希去重，防止重复处理相同的文段；
    - 调用LLM对文本提取命名实体；
    - 调用LLM对文本提取RDF关系；

    之后，LPMM会对处理后的数据进行重组织，将其转化为OpenIE格式进行保存。此时，文本已经被处理成了类似于下方的JSON数据结构：

    ```Json
    {
        "docs": [
            {
                "idx": "ef7ac76b35851b3d3921b0126381b4be",
                "passage": "[芽衣]这是……？\n[芽衣]和爱莉希雅给我的那枚徽章颇为相似的感觉... 但它的'重量'却明显比那枚徽章要薄弱许多。\n[芽衣]带回去给爱莉希雅看看吧。\n",
                "extracted_entities": [
                    "芽衣", "爱莉希雅", "徽章"
                ],
                "extracted_triples": [
                    [ "芽衣", "拥有", "徽章" ],
                    [ "芽衣", "提到", "它" ],
                    [ "芽衣", "带回去查看", "爱莉希雅" ],
                    [ "芽衣", "比较重量", "旧的徽章" ],
                ]
            },
        ],
        "avg_ent_chars": 1.0,
        "avg_ent_words": 1.0,
    }
    ```

2. **文本Embedding**
   
    LPMM会对文本进行Embedding，将文本转化为向量存储，以便后续的图谱构建。LPMM可以配置使用不同的Embedding模型，详见`config.toml`

    之后，LPMM会使用Faiss对Embedding库进行索引，以便后续的检索。

3. **构建知识图谱**

    LPMM会将预处理后的数据构建为RAG图谱，具体如下：

    1. 构建实体节点间的关系，将文段中的实体关系构建为图谱的边；
    2. 统计实体节点的权重，根据实体在所有文段中出现的次数进行计算（当实体在一个文段中多次出现时，只计一次）；
    3. 构建实体节点和文段节点的关系，将文段中的实体和他们所在的文段构建为图谱的边；
    4. 通过Embedding的余弦相似度，使用`Faiss`查找可能的近义词，将实体节点间的近义词关系构建成图谱的扩展边（如已有关系，则加在原有边的权重上）；
   
### 2. 在线检索

收到一条检索请求后，LPMM会对请求进行处理，具体如下：

1. **文本预处理**：对检索请求的文本（Query）进行Embedding，转化为向量；

2. **Embedding检索**：使用`Faiss`分别对`RelationEmbedding库`和`ParagraphEmbedding库`进行检索，找出top_k个备选关系和top_k个备选文段，以及它们与Query之间的相关性（余弦相似度）；（后者称为密集段落检索，DPR）
3. **LLM过滤**：使用LLM对检索结果进行过滤，保留对解决问题有帮助的Relation；
4. **检索结果**：根据过滤后有没有剩余的Relation，分为两种情况：
    - 若过滤后还有剩余的Relation，则对剩余的Relation提取主宾短语赋予对应的实体节点初始权重，同时结合DPR的结果赋予文段节点初始权重。之后，进行PersonalizedPageRank（PPR），获取初步的检索结果；
    - 若过滤后没有剩余的Relation，则直接使用DPR的结果作为初步检索结果；
5. **返回结果**：根据上一步中的检索结果，筛选top_k后，获取相应的文段，返回给用户。
